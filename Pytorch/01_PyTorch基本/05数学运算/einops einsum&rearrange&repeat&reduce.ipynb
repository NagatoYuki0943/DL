{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install & docs\n",
    "\n",
    "https://github.com/arogozhnikov/einops\n",
    "\n",
    "`pip install einops`\n",
    "\n",
    "einops 支持 **numpy, pytorch, tensorflow, keras, jax** 等\n",
    "\n",
    "einops所有操作的pattern的axis之间必须有空格\n",
    "\n",
    "```python\n",
    "einops.einsum\n",
    "    \"i j, k j -> i k\" ✅\n",
    "    \"i j, k j -> ik\"  ❌\n",
    "\n",
    "einops.rearrange\n",
    "    \"t (b c) -> b c t\" ✅\n",
    "    \"t (b c) -> b ct\"  ❌\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2a35a20ae50>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from einops import einsum, rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# einsum same as torch.einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random((1, 196, 768))\n",
    "b = np.random.random((1, 768, 196))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_t = torch.from_numpy(a)\n",
    "b_t = torch.from_numpy(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不需要转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 196, 196)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c0 = np.einsum(\"b p c, b c k -> b p k\", a, b)\n",
    "c0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 196, 196)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = einsum(a, b, \"b p c, b c k -> b p k\")\n",
    "c1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(c0==c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 196, 196])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c0_t = torch.einsum(\"b p c, b c k -> b p k\", a_t, b_t)    # 空格可有可无\n",
    "c0_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 196, 196])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1_t = einsum(a_t, b_t, \"b p c, b c k -> b p k\")          # einops所有操作的pattern的axis之间必须有空格\n",
    "c1_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(c0_t==c1_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 需要转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 196, 196)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2 = np.einsum(\"b p c, b k c -> b p k\", a, b.swapaxes(1, 2))\n",
    "c2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 196, 196)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3 = einsum(a, b.swapaxes(1, 2), \"b p c, b k c -> b p k\")\n",
    "c3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(c0==c1), np.all(c1==c2), np.all(c2==c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 196, 196])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2_t = torch.einsum(\"b p c, b k c -> b p k\", a_t, b_t.transpose(1, 2))\n",
    "c2_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 196, 196])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3_t = einsum(a_t, b_t.transpose(1, 2), \"b p c, b k c -> b p k\")\n",
    "c3_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), tensor(True), tensor(True))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(c0_t==c1_t), torch.all(c1_t==c2_t), torch.all(c2_t==c3_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rearrange: reshape, transopse, permute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 768, 196)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = np.ones((196, 10, 768))\n",
    "# rearrange elements according to the pattern\n",
    "rearrange(input_tensor, \"t b c -> b c t\").shape   # einops所有操作的pattern的axis之间必须有空格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 768, 196])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = torch.ones((196, 10, 768))\n",
    "# rearrange elements according to the pattern\n",
    "output_tensor0 = rearrange(input_tensor, \"t b c -> b c t\")   # einops所有操作的pattern的axis之间必须有空格\n",
    "output_tensor0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 768, 196])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrange_ = Rearrange(\"t b c -> b c t\")\n",
    "# rearrange elements according to the pattern\n",
    "output_tensor1 = rearrange_(input_tensor)\n",
    "output_tensor1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(output_tensor0==output_tensor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 768, 196])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = torch.ones((196, 10*768))\n",
    "# () 代表隐藏维度,需要指定内部值,不需要全部指定,可以推导出即可\n",
    "output_tensor2 = rearrange(input_tensor, \"t (b c) -> b c t\", b=10)  # einops所有操作的pattern的axis之间必须有空格\n",
    "output_tensor2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(output_tensor0==output_tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 变量使用多个字母"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1, 12, 196, 64)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = np.ones((1, 196, 3*768))\n",
    "output_tensor = rearrange(input_tensor, \"b n (qkv h d) -> qkv b h n d\", qkv = 3, h = 12)    # 不使用空格会当做单个变量\n",
    "output_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 12, 196, 64])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = torch.ones((1, 196, 3*768))\n",
    "output_tensor0 = rearrange(input_tensor, \"b n (qkv h d) -> qkv b h n d\", qkv = 3, h = 12)    # 不使用空格会当做单个变量\n",
    "output_tensor0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 12, 196, 64])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor1 = input_tensor.reshape(1, 196, 3, 12, -1).permute(2, 0, 3, 1, 4)\n",
    "output_tensor1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(output_tensor0==output_tensor1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reduce: rearrange + min/max/sum/mean/prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 32, 64)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randn(100, 32, 64)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 64)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform max-reduction on the first axis\n",
    "reduce(x, 't b c -> b c', 'max').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 64)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as previous, but with clearer axes meaning\n",
    "reduce(x, 'time batch channel -> batch channel', 'max').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20, 30, 40)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randn(10, 20, 30, 40)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20, 15, 20)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2d max-pooling with kernel size = 2 * 2 for image processing\n",
    "y1 = reduce(x, 'b c (h1 h2) (w1 w2) -> b c h1 w1', 'max', h2=2, w2=2)\n",
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5, 30, 40)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if one wants to go back to the original height and width, depth-to-space trick can be applied\n",
    "# 将 c 转换到 h w\n",
    "y2 = rearrange(y1, 'b (c h2 w2) h1 w1 -> b c (h1 h2) (w1 w2)', h2=2, w2=2)\n",
    "y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20, 3, 4)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adaptive 2d max-pooling to 3 * 4 grid\n",
    "reduce(x, 'b c (h1 h2) (w1 w2) -> b c h1 w1', 'max', h1=3, w1=4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Global average pooling\n",
    "reduce(x, 'b c h w -> b c', 'mean').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 20, 1, 1)\n",
      "(1, 20, 1, 1)\n",
      "(10, 20, 30, 40)\n"
     ]
    }
   ],
   "source": [
    "# Subtracting mean over batch for each channel\n",
    "print(reduce(x, 'b c h w -> () c () ()', 'mean').shape)\n",
    "print(reduce(x, 'b c h w -> 1 c 1 1', 'mean').shape)    # 1 same as ()\n",
    "print((x - reduce(x, 'b c h w -> () c () ()', 'mean')).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20, 1, 1)\n",
      "(10, 20, 30, 40)\n"
     ]
    }
   ],
   "source": [
    "# Subtracting per-image mean for each channel\n",
    "print(reduce(x, 'b c h w -> b c () ()', 'mean').shape)\n",
    "print((x - reduce(x, 'b c h w -> b c () ()', 'mean')).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# repeat: repeat, expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 40)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a grayscale image (of shape height x width)\n",
    "image = np.random.randn(30, 40)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 40, 3)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change it to RGB format by repeating in each channel\n",
    "repeat(image, 'h w -> h w c', c=3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 40)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 竖直重复2次图片\n",
    "# repeat image 2 times along height (vertical axis)\n",
    "repeat(image, 'h w -> (repeat h) w', repeat=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 120)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 水平重复2次,竖直重复3次\n",
    "# repeat image 2 time along height and 3 times along width\n",
    "repeat(image, 'h w -> (h2 h) (w3 w)', h2=2, w3=3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 80)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每个像素值重复为2x2大小,宽高翻倍\n",
    "# convert each pixel to a small square 2x2. Upsample image by 2x\n",
    "repeat(image, 'h w -> (h h2) (w w2)', h2=2, w2=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 20)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pixelate image first by downsampling by 2x\n",
    "downsampled = reduce(image, '(h h2) (w w2) -> h w', 'mean', h2=2, w2=2)\n",
    "downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 40)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then upsampling\n",
    "repeat(downsampled, 'h w -> (h h2) (w w2)', h2=2, w2=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
