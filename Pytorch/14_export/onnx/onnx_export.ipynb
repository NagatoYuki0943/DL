{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models\n",
    "import onnx\n",
    "import onnxsim\n",
    "from onnxsim import simplify\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.28'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnxsim.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "onnx_path = r\"resnet18.onnx\"\n",
    "torch.onnx.export(model,                        # 保存的模型\n",
    "                    x,                          # 模型输入\n",
    "                    onnx_path,                  # 模型保存 (can be a file or file-like object)\n",
    "                    verbose=False,              # 如果为True，则打印一些转换日志，并且onnx模型中会包含doc_string信息\n",
    "                    opset_version=16,           # ONNX version 值必须等于_onnx_main_opset或在_onnx_stable_opsets之内。具体可在torch/onnx/symbolic_helper.py中找到\n",
    "                    input_names=[\"image\"],      # 按顺序分配给onnx图的输入节点的名称列表\n",
    "                    output_names=[\"classes\"],   # 按顺序分配给onnx图的输出节点的名称列表\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = onnx.load(onnx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_, ok = simplify(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.save(model_, \"resnet18.sim.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ort_run(onnx_path, x):\n",
    "    so = ort.SessionOptions()\n",
    "    so.log_severity_level = 3\n",
    "    ort_model = ort.InferenceSession(onnx_path, sess_options=so, providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "    res = ort_model.run(None, {ort_model.get_inputs()[0].name: x})\n",
    "    print(res[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1000)\n"
     ]
    }
   ],
   "source": [
    "ort_run(\"resnet18.sim.onnx\", np.ones((1, 3, 224, 224), dtype=np.float32))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_onnx(model, input, onnx_path, dynamic_axes=False, half=False):\n",
    "    if half: # half不支持cpu导出,必须使用cuda\n",
    "        model = model.half()\n",
    "        input = input.half()\n",
    "    model.eval()\n",
    "    torch.onnx.export(model,                        # 保存的模型\n",
    "                        input,                      # 模型输入\n",
    "                        onnx_path,                  # 模型保存 (can be a file or file-like object)\n",
    "                        export_params=True,         # 如果指定为True或默认, 参数也会被导出. 如果你要导出一个没训练过的就设为 False.\n",
    "                        verbose=False,              # 如果为True，则打印一些转换日志，并且onnx模型中会包含doc_string信息\n",
    "                        opset_version=16,           # ONNX version 值必须等于_onnx_main_opset或在_onnx_stable_opsets之内。具体可在torch/onnx/symbolic_helper.py中找到\n",
    "                        do_constant_folding=True,   # 是否使用\"常量折叠\"优化。常量折叠将使用一些算好的常量来优化一些输入全为常量的节点。\n",
    "                        input_names=[\"image\"],      # 按顺序分配给onnx图的输入节点的名称列表\n",
    "                        output_names=[\"classes\"],   # 按顺序分配给onnx图的输出节点的名称列表\n",
    "                        # 动态形状,初始通道不要变换,transformer使用dynamic可能会有问题\n",
    "                        dynamic_axes={\"image\": {0: \"batch_size\", 2: \"height\", 3:\"width\"}, \"classes\": {0: \"batch_size\"}} if dynamic_axes else None\n",
    "                        )\n",
    "\n",
    "    # 载入onnx模型\n",
    "    model_ = onnx.load(onnx_path)\n",
    "\n",
    "    # 检查IR是否良好\n",
    "    try:\n",
    "        onnx.checker.check_model(model_)\n",
    "    except Exception:\n",
    "        print(f\"{onnx_path} incorrect\")\n",
    "    else:\n",
    "        print(f\"{onnx_path} correct\")\n",
    "\n",
    "    # 简化模型\n",
    "    model_simple, check = simplify(model_)\n",
    "    assert check, \"Simplified ONNX model could not be validated\"\n",
    "    onnx.save(model_simple, onnx_path)\n",
    "    print(\"simplified ONNX model success\")\n",
    "    print('finished exporting ' + onnx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "resnet18.onnx correct\n",
      "simplified ONNX model success\n",
      "finished exporting resnet18.onnx\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "resnet18.half.onnx correct\n",
      "simplified ONNX model success\n",
      "finished exporting resnet18.half.onnx\n"
     ]
    }
   ],
   "source": [
    "input = torch.ones(1, 3, 224, 224)\n",
    "resnet18 = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "export_onnx(resnet18, input, \"resnet18.onnx\", dynamic_axes=True)\n",
    "export_onnx(resnet18.cuda(0), input.cuda(0), \"resnet18.half.onnx\", dynamic_axes=True, half=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1000)\n"
     ]
    }
   ],
   "source": [
    "ort_run(\"resnet18.half.onnx\", np.ones((1, 3, 224, 224), dtype=np.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_b0 = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "export_onnx(efficientnet_b0, input, \"efficientnet_b0.onnx\", dynamic_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "twins_svt_small = timm.models.twins_svt_small(num_classes=10)\n",
    "export_onnx(twins_svt_small, input, \"twins_svt_small.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
