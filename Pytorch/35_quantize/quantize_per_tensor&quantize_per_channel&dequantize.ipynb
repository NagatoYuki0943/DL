{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b64b9512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81bb642",
   "metadata": {},
   "source": [
    "# quantize_per_tensor&dequantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13c382de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 创建一个普通的浮点张量\n",
    "original_float = torch.tensor([-1.52, 0.01, 1.501, 3.0001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "709a8923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 定义量化参数\n",
    "scale = 0.5\n",
    "zero_point = 0\n",
    "dtype = torch.qint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae3d7820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "量化后的张量 (int8): tensor([-1.5000,  0.0000,  1.5000,  3.0000], size=(4,), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.5, zero_point=0)\n",
      "存储的整数值: tensor([-3,  0,  3,  6], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "# 3. 量化：将 float32 -> qint8\n",
    "# 公式：q = round(x / scale + zero_point)\n",
    "q_tensor = torch.quantize_per_tensor(original_float, scale, zero_point, dtype)\n",
    "\n",
    "print(f\"量化后的张量 (int8): {q_tensor}\")\n",
    "print(f\"存储的整数值: {q_tensor.int_repr()}\") # 查看底层的 int8 数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78f60f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "反量化后的张量 (float32): tensor([-1.5000,  0.0000,  1.5000,  3.0000])\n"
     ]
    }
   ],
   "source": [
    "# 4. 反量化：将 qint8 -> float32\n",
    "# 公式：x = (q - zero_point) * scale\n",
    "dequantized_tensor = torch.dequantize(q_tensor)\n",
    "# 或者使用对象方法: q_tensor.dequantize()\n",
    "\n",
    "print(f\"反量化后的张量 (float32): {dequantized_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "精度损失: tensor([-2.0000e-02,  1.0000e-02,  1.0000e-03,  9.9897e-05])\n"
     ]
    }
   ],
   "source": [
    "# 5. 观察误差\n",
    "# 注意：反量化后的值可能与原始值不完全相等，因为量化是“有损”的\n",
    "error = original_float - dequantized_tensor\n",
    "print(f\"精度损失: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d950ca7d",
   "metadata": {},
   "source": [
    "# quantize_per_channel&dequantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed7d0150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000e-01,  0.0000e+00,  1.0000e-01,  2.0000e-01],\n",
       "        [-1.0000e+02, -5.0000e+01,  0.0000e+00,  5.0000e+01],\n",
       "        [-1.1000e+02, -6.0000e+01,  2.0000e+01,  4.0000e+01],\n",
       "        [-5.0000e+00, -2.5000e+00,  2.5000e+00,  5.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 准备数据\n",
    "# 模拟一个 (4, 4) 的权重矩阵\n",
    "# 假设有 4 个输出通道 (axis 0)，每个通道有 4 个输入特征\n",
    "# 我们故意让不同通道的数值范围差异很大，以体现 Per-Channel 的优势\n",
    "original_weights = torch.tensor([\n",
    "    [-0.1, 0.0, 0.1, 0.2],    # 通道 0: 数值很小\n",
    "    [-100, -50, 0, 50],       # 通道 1: 数值很大\n",
    "    [-110, -60, 20, 40],      # 通道 2: 数值很大\n",
    "    [-5.0, -2.5, 2.5, 5.0],   # 通道 3: 数值中等\n",
    "    [0.0, 0.0, 0.0, 0.0]      # 通道 4: 全是 0\n",
    "], dtype=torch.float32)\n",
    "original_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e95364d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 定义量化参数 (Per Channel)\n",
    "# 因为有 4 个通道 (dim=0)，我们需要 4 个 scale 和 4 个 zero_point\n",
    "# axis=0 表示我们将沿着第 0 维（行）应用不同的量化参数\n",
    "channel_axis = 0\n",
    "\n",
    "# 手动定义 scale (通常这是通过观察数据 min/max 计算出来的，这里为了演示手动指定)\n",
    "# 通道 0 范围小 -> scale 小\n",
    "# 通道 1 范围大 -> scale 大\n",
    "scales = torch.tensor([0.002, 0.5, 0.6, 0.05, 1.0])\n",
    "\n",
    "# 定义 zero_points (int8 范围是 -128 到 127)\n",
    "zero_points = torch.tensor([0, 0, 0, 0, 0])\n",
    "\n",
    "# 指定量化数据类型，通常权重使用 qint8 (有符号 8 位整数)\n",
    "dtype = torch.qint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "388bab4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "量化后的张量 (qint8):\n",
      "tensor([[ -0.1000,   0.0000,   0.1000,   0.2000],\n",
      "        [-64.0000, -50.0000,   0.0000,  50.0000],\n",
      "        [-76.8000, -60.0000,  19.8000,  40.2000],\n",
      "        [ -5.0000,  -2.5000,   2.5000,   5.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,   0.0000]], size=(5, 4),\n",
      "       dtype=torch.qint8, quantization_scheme=torch.per_channel_affine,\n",
      "       scale=tensor([0.0020, 0.5000, 0.6000, 0.0500, 1.0000], dtype=torch.float64),\n",
      "       zero_point=tensor([0, 0, 0, 0, 0]), axis=0)\n",
      "底层存储的整数值 (int_repr):\n",
      "tensor([[ -50,    0,   50,  100],\n",
      "        [-128, -100,    0,  100],\n",
      "        [-128, -100,   33,   67],\n",
      "        [-100,  -50,   50,  100],\n",
      "        [   0,    0,    0,    0]], dtype=torch.int8)\n",
      "--------------------\n",
      "查看每个通道的 Scale: tensor([0.0020, 0.5000, 0.6000, 0.0500, 1.0000], dtype=torch.float64)\n",
      "查看每个通道的 Zero Point: tensor([0, 0, 0, 0, 0])\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# 3. 执行 Per-Channel 量化\n",
    "# quantize_per_channel(input, scales, zero_points, axis, dtype)\n",
    "q_weights = torch.quantize_per_channel(original_weights, scales, zero_points, channel_axis, dtype)\n",
    "\n",
    "print(f\"量化后的张量 (qint8):\\n{q_weights}\")\n",
    "print(f\"底层存储的整数值 (int_repr):\\n{q_weights.int_repr()}\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"查看每个通道的 Scale: {q_weights.q_per_channel_scales()}\")\n",
    "print(f\"查看每个通道的 Zero Point: {q_weights.q_per_channel_zero_points()}\")\n",
    "print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ecfb2f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.1000,   0.0000,   0.1000,   0.2000],\n",
       "        [-64.0000, -50.0000,   0.0000,  50.0000],\n",
       "        [-76.8000, -60.0000,  19.8000,  40.2000],\n",
       "        [ -5.0000,  -2.5000,   2.5000,   5.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 执行反量化 (Dequantize)\n",
    "# dequantize 会自动读取张量内部存储的 per_channel 信息进行解码\n",
    "# 不需要再次传入 scales 或 zero_points\n",
    "recovered_weights = torch.dequantize(q_weights)\n",
    "# 也可以写成: recovered_weights = q_weights.dequantize()\n",
    "recovered_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d8212f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-3.6000e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-3.3200e+01,  3.8147e-06,  2.0000e-01, -2.0000e-01],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. 验证误差\n",
    "error = original_weights - recovered_weights\n",
    "error\n",
    "\n",
    "# 验证逻辑：反量化值 = (int_val - zp) * scale\n",
    "# 以通道 1 的第一个元素为例: 原始 -100, scale 0.5, zp 0\n",
    "# int_val = -100 / 0.5 = -200 -> clamp 到 -128 (int8下限)\n",
    "# dequant = -128 * 0.5 = -64\n",
    "# 误差 = -100 - (-64) = -36 (这是因为 range 设置不合理导致的截断，仅作演示)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e4bfdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
