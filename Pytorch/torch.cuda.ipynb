{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.is_bf16_supported()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sm_37',\n",
       " 'sm_50',\n",
       " 'sm_60',\n",
       " 'sm_61',\n",
       " 'sm_70',\n",
       " 'sm_75',\n",
       " 'sm_80',\n",
       " 'sm_86',\n",
       " 'sm_90',\n",
       " 'compute_37']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cuda.get_arch_list()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x18229341c90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.get_device_name(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_CudaDeviceProperties(name='NVIDIA GeForce GTX 1080 Ti', major=6, minor=1, total_memory=11263MB, multi_processor_count=28)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cuda.get_device_properties(torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.get_device_capability()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# allocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'native'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.get_allocator_backend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gencode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-gencode compute=compute_37,code=sm_37 -gencode compute=compute_50,code=sm_50 -gencode compute=compute_60,code=sm_60 -gencode compute=compute_61,code=sm_61 -gencode compute=compute_70,code=sm_70 -gencode compute=compute_75,code=sm_75 -gencode compute=compute_80,code=sm_80 -gencode compute=compute_86,code=sm_86 -gencode compute=compute_90,code=sm_90 -gencode compute=compute_37,code=compute_37'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.get_gencode_flags()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 171, 202, 224, 204,   6,  54,  14,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.get_rng_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "         255, 255, 171, 202, 224, 204,   6,  54,  14,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0], dtype=torch.uint8)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.get_rng_state_all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10094153728, 11810897920)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.mem_get_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cuda.memory_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cuda.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cuda.memory_reserved()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\cuda\\memory.py:416: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.memory_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.memory_snapshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('active.all.allocated', 0),\n",
       "             ('active.all.current', 0),\n",
       "             ('active.all.freed', 0),\n",
       "             ('active.all.peak', 0),\n",
       "             ('active.large_pool.allocated', 0),\n",
       "             ('active.large_pool.current', 0),\n",
       "             ('active.large_pool.freed', 0),\n",
       "             ('active.large_pool.peak', 0),\n",
       "             ('active.small_pool.allocated', 0),\n",
       "             ('active.small_pool.current', 0),\n",
       "             ('active.small_pool.freed', 0),\n",
       "             ('active.small_pool.peak', 0),\n",
       "             ('active_bytes.all.allocated', 0),\n",
       "             ('active_bytes.all.current', 0),\n",
       "             ('active_bytes.all.freed', 0),\n",
       "             ('active_bytes.all.peak', 0),\n",
       "             ('active_bytes.large_pool.allocated', 0),\n",
       "             ('active_bytes.large_pool.current', 0),\n",
       "             ('active_bytes.large_pool.freed', 0),\n",
       "             ('active_bytes.large_pool.peak', 0),\n",
       "             ('active_bytes.small_pool.allocated', 0),\n",
       "             ('active_bytes.small_pool.current', 0),\n",
       "             ('active_bytes.small_pool.freed', 0),\n",
       "             ('active_bytes.small_pool.peak', 0),\n",
       "             ('allocated_bytes.all.allocated', 0),\n",
       "             ('allocated_bytes.all.current', 0),\n",
       "             ('allocated_bytes.all.freed', 0),\n",
       "             ('allocated_bytes.all.peak', 0),\n",
       "             ('allocated_bytes.large_pool.allocated', 0),\n",
       "             ('allocated_bytes.large_pool.current', 0),\n",
       "             ('allocated_bytes.large_pool.freed', 0),\n",
       "             ('allocated_bytes.large_pool.peak', 0),\n",
       "             ('allocated_bytes.small_pool.allocated', 0),\n",
       "             ('allocated_bytes.small_pool.current', 0),\n",
       "             ('allocated_bytes.small_pool.freed', 0),\n",
       "             ('allocated_bytes.small_pool.peak', 0),\n",
       "             ('allocation.all.allocated', 0),\n",
       "             ('allocation.all.current', 0),\n",
       "             ('allocation.all.freed', 0),\n",
       "             ('allocation.all.peak', 0),\n",
       "             ('allocation.large_pool.allocated', 0),\n",
       "             ('allocation.large_pool.current', 0),\n",
       "             ('allocation.large_pool.freed', 0),\n",
       "             ('allocation.large_pool.peak', 0),\n",
       "             ('allocation.small_pool.allocated', 0),\n",
       "             ('allocation.small_pool.current', 0),\n",
       "             ('allocation.small_pool.freed', 0),\n",
       "             ('allocation.small_pool.peak', 0),\n",
       "             ('inactive_split.all.allocated', 0),\n",
       "             ('inactive_split.all.current', 0),\n",
       "             ('inactive_split.all.freed', 0),\n",
       "             ('inactive_split.all.peak', 0),\n",
       "             ('inactive_split.large_pool.allocated', 0),\n",
       "             ('inactive_split.large_pool.current', 0),\n",
       "             ('inactive_split.large_pool.freed', 0),\n",
       "             ('inactive_split.large_pool.peak', 0),\n",
       "             ('inactive_split.small_pool.allocated', 0),\n",
       "             ('inactive_split.small_pool.current', 0),\n",
       "             ('inactive_split.small_pool.freed', 0),\n",
       "             ('inactive_split.small_pool.peak', 0),\n",
       "             ('inactive_split_bytes.all.allocated', 0),\n",
       "             ('inactive_split_bytes.all.current', 0),\n",
       "             ('inactive_split_bytes.all.freed', 0),\n",
       "             ('inactive_split_bytes.all.peak', 0),\n",
       "             ('inactive_split_bytes.large_pool.allocated', 0),\n",
       "             ('inactive_split_bytes.large_pool.current', 0),\n",
       "             ('inactive_split_bytes.large_pool.freed', 0),\n",
       "             ('inactive_split_bytes.large_pool.peak', 0),\n",
       "             ('inactive_split_bytes.small_pool.allocated', 0),\n",
       "             ('inactive_split_bytes.small_pool.current', 0),\n",
       "             ('inactive_split_bytes.small_pool.freed', 0),\n",
       "             ('inactive_split_bytes.small_pool.peak', 0),\n",
       "             ('max_split_size', -1),\n",
       "             ('num_alloc_retries', 0),\n",
       "             ('num_ooms', 0),\n",
       "             ('oversize_allocations.allocated', 0),\n",
       "             ('oversize_allocations.current', 0),\n",
       "             ('oversize_allocations.freed', 0),\n",
       "             ('oversize_allocations.peak', 0),\n",
       "             ('oversize_segments.allocated', 0),\n",
       "             ('oversize_segments.current', 0),\n",
       "             ('oversize_segments.freed', 0),\n",
       "             ('oversize_segments.peak', 0),\n",
       "             ('requested_bytes.all.allocated', 0),\n",
       "             ('requested_bytes.all.current', 0),\n",
       "             ('requested_bytes.all.freed', 0),\n",
       "             ('requested_bytes.all.peak', 0),\n",
       "             ('requested_bytes.large_pool.allocated', 0),\n",
       "             ('requested_bytes.large_pool.current', 0),\n",
       "             ('requested_bytes.large_pool.freed', 0),\n",
       "             ('requested_bytes.large_pool.peak', 0),\n",
       "             ('requested_bytes.small_pool.allocated', 0),\n",
       "             ('requested_bytes.small_pool.current', 0),\n",
       "             ('requested_bytes.small_pool.freed', 0),\n",
       "             ('requested_bytes.small_pool.peak', 0),\n",
       "             ('reserved_bytes.all.allocated', 0),\n",
       "             ('reserved_bytes.all.current', 0),\n",
       "             ('reserved_bytes.all.freed', 0),\n",
       "             ('reserved_bytes.all.peak', 0),\n",
       "             ('reserved_bytes.large_pool.allocated', 0),\n",
       "             ('reserved_bytes.large_pool.current', 0),\n",
       "             ('reserved_bytes.large_pool.freed', 0),\n",
       "             ('reserved_bytes.large_pool.peak', 0),\n",
       "             ('reserved_bytes.small_pool.allocated', 0),\n",
       "             ('reserved_bytes.small_pool.current', 0),\n",
       "             ('reserved_bytes.small_pool.freed', 0),\n",
       "             ('reserved_bytes.small_pool.peak', 0),\n",
       "             ('segment.all.allocated', 0),\n",
       "             ('segment.all.current', 0),\n",
       "             ('segment.all.freed', 0),\n",
       "             ('segment.all.peak', 0),\n",
       "             ('segment.large_pool.allocated', 0),\n",
       "             ('segment.large_pool.current', 0),\n",
       "             ('segment.large_pool.freed', 0),\n",
       "             ('segment.large_pool.peak', 0),\n",
       "             ('segment.small_pool.allocated', 0),\n",
       "             ('segment.small_pool.current', 0),\n",
       "             ('segment.small_pool.freed', 0),\n",
       "             ('segment.small_pool.peak', 0)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cuda.memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.max_memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.max_memory_reserved()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\cuda\\memory.py:424: FutureWarning: torch.cuda.max_memory_cached has been renamed to torch.cuda.max_memory_reserved\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.max_memory_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
